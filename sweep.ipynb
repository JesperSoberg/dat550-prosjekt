{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\n",
    "        \"goal\": \"maximize\",\n",
    "        \"name\": \"Macro-f1-score\"\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"batch_size\": {\n",
    "            \"distribution\": \"int_uniform\",\n",
    "            \"max\": 112,\n",
    "            \"min\": 13\n",
    "        },\n",
    "        \"bow\": {\n",
    "            \"distribution\": \"categorical\",\n",
    "            \"values\": [\"tf_idf\", \"countVector\"]\n",
    "        },\n",
    "        \"hidden_size\": {\n",
    "            \"distribution\": \"int_uniform\",\n",
    "            \"max\": 208,\n",
    "            \"min\": 25\n",
    "        },\n",
    "        \"learning_rate\": {\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"max\": 0.0030063894350760606,\n",
    "            \"min\": 0.0004767494294738798\n",
    "        },\n",
    "        \"network\": {\n",
    "            \"distribution\": \"categorical\",\n",
    "            \"values\": [\"rnn\", \"ffnn\"]\n",
    "        },\n",
    "        \"nrows\": {\n",
    "            \"distribution\": \"int_uniform\",\n",
    "            \"max\": 324,\n",
    "            \"min\": 35\n",
    "        },\n",
    "        \"num_epochs\": {\n",
    "            \"distribution\": \"int_uniform\",\n",
    "            \"max\": 90,\n",
    "            \"min\": 15\n",
    "        },\n",
    "        \"num_layers\": {\n",
    "            \"distribution\": \"int_uniform\",\n",
    "            \"max\": 2,\n",
    "            \"min\": 1\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the function to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataSet import CustomDataDataSet\n",
    "from rnn import RNN\n",
    "from ffnn import FFNN\n",
    "from Preprocessing import getDataFrameFromData\n",
    "from BoW import TF_IDF, getCountVector\n",
    "from networkFunctions import train, test\n",
    "\n",
    "def sweep(config=None):\n",
    "    torch.manual_seed(888)\n",
    "    np.random.seed(888)\n",
    "    \n",
    "    with wandb.init(config=config):\n",
    "\n",
    "        config = wandb.config\n",
    "\n",
    "        train_df, train_labels = getDataFrameFromData(\"Archive/arxiv_train.csv\", nrows=config.nrows)\n",
    "        test_df, test_labels = getDataFrameFromData(\"Archive/arxiv_test.csv\", nrows=config.nrows)\n",
    "\n",
    "        if config.bow == \"tf_idf\":\n",
    "            train_tensors, vocabulary = TF_IDF(train_df)\n",
    "            test_tensors, _ = TF_IDF(test_df, vocabulary=vocabulary)\n",
    "        elif config.bow == \"countVector\":\n",
    "            train_tensors, vocabulary = getCountVector(train_df)\n",
    "            test_tensors, _ = getCountVector(test_df, vocabulary=vocabulary)\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "        train_dataset = CustomDataDataSet(train_tensors, train_labels)\n",
    "        test_dataset = CustomDataDataSet(test_tensors, test_labels)\n",
    "        train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                                    batch_size=config.batch_size,\n",
    "                                    shuffle=True)\n",
    "        test_dataloader = DataLoader(dataset=test_dataset,\n",
    "                                    batch_size=config.batch_size,\n",
    "                                    shuffle=True)\n",
    "        \n",
    "        if config.network == \"rnn\":\n",
    "            print(train_tensors.shape[1])\n",
    "            model = RNN(train_tensors.shape[1],\n",
    "                        config.hidden_size,\n",
    "                        config.num_layers)\n",
    "        elif config.network == \"ffnn\":\n",
    "            model = FFNN(train_tensors.shape[1])\n",
    "        else:\n",
    "            return\n",
    "            \n",
    "        loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "        optimiser = torch.optim.Adam(model.parameters(),\n",
    "                                        lr=config.learning_rate)\n",
    "    \n",
    "        for _ in range(config.num_epochs):\n",
    "            train(train_dataloader, model, optimiser, loss_function)\n",
    "            test(test_dataloader, model, loss_function)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inistialise the sweep. NB! Skip if already created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 48m0nanw\n",
      "Sweep URL: https://wandb.ai/j-soberg/RNNs%20and%20You/sweeps/48m0nanw\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(config, project=\"RNNs and You\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a sweep agent, using count to specify how many runs (optional). If run already exists, then copy the id from W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ep99j5i2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 81\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbow: countVector\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 177\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007613591049743388\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnetwork: rnn\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnrows: 303\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 67\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mj-soberg\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\jespe\\git\\550dat\\prosjekt\\wandb\\run-20240419_074451-ep99j5i2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/j-soberg/RNNs%20and%20You/runs/ep99j5i2' target=\"_blank\">wise-sweep-1</a></strong> to <a href='https://wandb.ai/j-soberg/RNNs%20and%20You' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/j-soberg/RNNs%20and%20You/sweeps/48m0nanw' target=\"_blank\">https://wandb.ai/j-soberg/RNNs%20and%20You/sweeps/48m0nanw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/j-soberg/RNNs%20and%20You' target=\"_blank\">https://wandb.ai/j-soberg/RNNs%20and%20You</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/j-soberg/RNNs%20and%20You/sweeps/48m0nanw' target=\"_blank\">https://wandb.ai/j-soberg/RNNs%20and%20You/sweeps/48m0nanw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/j-soberg/RNNs%20and%20You/runs/ep99j5i2' target=\"_blank\">https://wandb.ai/j-soberg/RNNs%20and%20You/runs/ep99j5i2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7523\n",
      "loss: 2.302272081375122  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.2607260726072607, Precision: 0.21950741475623375, recall: 0.22659511241290944, f1: 0.22163785316112244, Avg loss: 2.2998823523521423 \n",
      "\n",
      "loss: 2.296083688735962  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.33993399339933994, Precision: 0.3055924740481237, recall: 0.31317978276537234, f1: 0.3059614485441516, Avg loss: 2.2977689504623413 \n",
      "\n",
      "loss: 2.287703514099121  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.41254125412541254, Precision: 0.38574626303512854, recall: 0.3887538481710807, f1: 0.38395404658526655, Avg loss: 2.294773817062378 \n",
      "\n",
      "loss: 2.2745275497436523  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.41914191419141916, Precision: 0.39929458119149563, recall: 0.405927135620583, f1: 0.3991755454421352, Avg loss: 2.2916170358657837 \n",
      "\n",
      "loss: 2.2643446922302246  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.4752475247524752, Precision: 0.45725638843859784, recall: 0.4566176004506546, f1: 0.450724586148315, Avg loss: 2.287721335887909 \n",
      "\n",
      "loss: 2.250776529312134  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.5247524752475248, Precision: 0.5147744283286333, recall: 0.5146422338281409, f1: 0.5098750919199302, Avg loss: 2.284171938896179 \n",
      "\n",
      "loss: 2.2354400157928467  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.5610561056105611, Precision: 0.5537136343777291, recall: 0.555776950962858, f1: 0.5487825516617834, Avg loss: 2.280202090740204 \n",
      "\n",
      "loss: 2.219818592071533  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.5478547854785478, Precision: 0.5458330386682151, recall: 0.5508736115674118, f1: 0.5416741501189394, Avg loss: 2.276502788066864 \n",
      "\n",
      "loss: 2.213623523712158  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.594059405940594, Precision: 0.5921317252921451, recall: 0.5926877708168827, f1: 0.5852118540531612, Avg loss: 2.272058665752411 \n",
      "\n",
      "loss: 2.202383041381836  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.5775577557755776, Precision: 0.5715214556948429, recall: 0.5688409805368091, f1: 0.5634132209499471, Avg loss: 2.2690770626068115 \n",
      "\n",
      "loss: 2.199591636657715  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.594059405940594, Precision: 0.5937898210824442, recall: 0.5835728232630076, f1: 0.5809376337946811, Avg loss: 2.263452708721161 \n",
      "\n",
      "loss: 2.196474075317383  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6171617161716172, Precision: 0.6177542852653117, recall: 0.6101135908738873, f1: 0.6061035886514522, Avg loss: 2.261577844619751 \n",
      "\n",
      "loss: 2.195559501647949  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6237623762376238, Precision: 0.6293099277936235, recall: 0.624033707200124, f1: 0.6192741231564761, Avg loss: 2.2586413621902466 \n",
      "\n",
      "loss: 2.1951913833618164  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6171617161716172, Precision: 0.605627902354126, recall: 0.6141708507234568, f1: 0.6033071563166873, Avg loss: 2.2573887705802917 \n",
      "\n",
      "loss: 2.1978862285614014  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6237623762376238, Precision: 0.6333907251247657, recall: 0.6281751361983305, f1: 0.6202625133591984, Avg loss: 2.2543434500694275 \n",
      "\n",
      "loss: 2.194450616836548  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6039603960396039, Precision: 0.5986297115867545, recall: 0.5936566564092801, f1: 0.5906552930457941, Avg loss: 2.2532073855400085 \n",
      "\n",
      "loss: 2.1947662830352783  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.636963696369637, Precision: 0.6412023101029268, recall: 0.6359430997350567, f1: 0.6276937334649415, Avg loss: 2.2548967003822327 \n",
      "\n",
      "loss: 2.194182872772217  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.594059405940594, Precision: 0.6021772597190953, recall: 0.5924916850990579, f1: 0.5857798101847862, Avg loss: 2.2524750232696533 \n",
      "\n",
      "loss: 2.1938300132751465  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6039603960396039, Precision: 0.6165945734914479, recall: 0.5967353196920178, f1: 0.5967813684064229, Avg loss: 2.2530173659324646 \n",
      "\n",
      "loss: 2.205162525177002  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.594059405940594, Precision: 0.6052442868468112, recall: 0.5885264814263844, f1: 0.587485593862024, Avg loss: 2.253214716911316 \n",
      "\n",
      "loss: 2.1940557956695557  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6204620462046204, Precision: 0.6255131362889983, recall: 0.6185383729165368, f1: 0.6142270248010532, Avg loss: 2.2514493465423584 \n",
      "\n",
      "loss: 2.194439649581909  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6303630363036303, Precision: 0.640559748314609, recall: 0.6346204839474969, f1: 0.6263927191634717, Avg loss: 2.2500173449516296 \n",
      "\n",
      "loss: 2.1933720111846924  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6237623762376238, Precision: 0.6261259698611142, recall: 0.6251499113260293, f1: 0.6128311929274154, Avg loss: 2.2491822242736816 \n",
      "\n",
      "loss: 2.193512439727783  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6138613861386139, Precision: 0.6231412976759112, recall: 0.6091535106181019, f1: 0.6067800418763111, Avg loss: 2.2512052059173584 \n",
      "\n",
      "loss: 2.1938183307647705  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6138613861386139, Precision: 0.6218302527253934, recall: 0.6115586667271119, f1: 0.6077748241299169, Avg loss: 2.2487872838974 \n",
      "\n",
      "loss: 2.194127082824707  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6138613861386139, Precision: 0.6101139277389278, recall: 0.6105842278171407, f1: 0.6025695209439225, Avg loss: 2.249027967453003 \n",
      "\n",
      "loss: 2.1931111812591553  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6039603960396039, Precision: 0.6147864813560081, recall: 0.6024359349808683, f1: 0.5966667312325387, Avg loss: 2.245176672935486 \n",
      "\n",
      "loss: 2.1934494972229004  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6039603960396039, Precision: 0.6195876188216772, recall: 0.6002422498439783, f1: 0.5976942030457295, Avg loss: 2.246319055557251 \n",
      "\n",
      "loss: 2.1931304931640625  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.594059405940594, Precision: 0.6026619664684181, recall: 0.5884935383346178, f1: 0.5851137368828172, Avg loss: 2.249317944049835 \n",
      "\n",
      "loss: 2.1932413578033447  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6171617161716172, Precision: 0.6224790084437946, recall: 0.6172693225318677, f1: 0.6100357866274112, Avg loss: 2.2447991967201233 \n",
      "\n",
      "loss: 2.1938085556030273  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6138613861386139, Precision: 0.619219978586636, recall: 0.6098456821650224, f1: 0.6039362439313645, Avg loss: 2.2475139498710632 \n",
      "\n",
      "loss: 2.193589687347412  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6039603960396039, Precision: 0.6112981135784251, recall: 0.5986601270577812, f1: 0.5942946225122914, Avg loss: 2.243850588798523 \n",
      "\n",
      "loss: 2.1935579776763916  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6138613861386139, Precision: 0.6256933473257251, recall: 0.6165091479972863, f1: 0.6067217059843406, Avg loss: 2.245918333530426 \n",
      "\n",
      "loss: 2.1931731700897217  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6072607260726073, Precision: 0.6217709625989472, recall: 0.6073466757248396, f1: 0.6006943400628961, Avg loss: 2.2466307282447815 \n",
      "\n",
      "loss: 2.193417549133301  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.636963696369637, Precision: 0.6565225286144234, recall: 0.637582839227517, f1: 0.6350981324362316, Avg loss: 2.2444067001342773 \n",
      "\n",
      "loss: 2.193143606185913  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.5973597359735974, Precision: 0.6135399452338444, recall: 0.6001575004711965, f1: 0.5935961309960375, Avg loss: 2.2456798553466797 \n",
      "\n",
      "loss: 2.1932876110076904  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.594059405940594, Precision: 0.6033240270574809, recall: 0.5951934759834046, f1: 0.5874631191745268, Avg loss: 2.242896556854248 \n",
      "\n",
      "loss: 2.193074941635132  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6039603960396039, Precision: 0.6218106659822745, recall: 0.6051173808700046, f1: 0.5996896496226902, Avg loss: 2.242796003818512 \n",
      "\n",
      "loss: 2.1930694580078125  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.5907590759075908, Precision: 0.616181917610928, recall: 0.5942579496361134, f1: 0.5879735841192985, Avg loss: 2.243792951107025 \n",
      "\n",
      "loss: 2.193223714828491  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6072607260726073, Precision: 0.6098757914275451, recall: 0.6050155599855749, f1: 0.5976131185893286, Avg loss: 2.2451553344726562 \n",
      "\n",
      "loss: 2.192880153656006  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6006600660066007, Precision: 0.6150637408568442, recall: 0.6046836383575073, f1: 0.5959539508110937, Avg loss: 2.2445217967033386 \n",
      "\n",
      "loss: 2.192882776260376  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6039603960396039, Precision: 0.6232429547935808, recall: 0.5997333169585572, f1: 0.5995207196051024, Avg loss: 2.2419654726982117 \n",
      "\n",
      "loss: 2.1936111450195312  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6237623762376238, Precision: 0.6399862852664577, recall: 0.6293819254992199, f1: 0.6205006558984121, Avg loss: 2.240319013595581 \n",
      "\n",
      "loss: 2.193049907684326  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6171617161716172, Precision: 0.6369055431961439, recall: 0.6196142721571772, f1: 0.6135846447428283, Avg loss: 2.242933690547943 \n",
      "\n",
      "loss: 2.1928842067718506  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6105610561056105, Precision: 0.6310137674384497, recall: 0.6112192423503827, f1: 0.607672645779037, Avg loss: 2.2427159547805786 \n",
      "\n",
      "loss: 2.193267345428467  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6006600660066007, Precision: 0.6189872268166992, recall: 0.6035218353977505, f1: 0.597275268231157, Avg loss: 2.2427643537521362 \n",
      "\n",
      "loss: 2.192991018295288  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.5874587458745875, Precision: 0.6019360269360269, recall: 0.5835496629692767, f1: 0.5821801473268884, Avg loss: 2.2431673407554626 \n",
      "\n",
      "loss: 2.1930253505706787  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.5907590759075908, Precision: 0.599196060978041, recall: 0.5870589220939341, f1: 0.5819721312402646, Avg loss: 2.243772268295288 \n",
      "\n",
      "loss: 2.192843198776245  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6204620462046204, Precision: 0.6334391379081277, recall: 0.6248170468382128, f1: 0.6175796848803667, Avg loss: 2.2424827814102173 \n",
      "\n",
      "loss: 2.1928679943084717  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6237623762376238, Precision: 0.6405173817242782, recall: 0.6204662453661484, f1: 0.6196218131016507, Avg loss: 2.240362048149109 \n",
      "\n",
      "loss: 2.192887783050537  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6105610561056105, Precision: 0.6324636752136753, recall: 0.6139071623421214, f1: 0.6110797192926439, Avg loss: 2.241224467754364 \n",
      "\n",
      "loss: 2.1930246353149414  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6402640264026402, Precision: 0.6533586163038968, recall: 0.6364556856456495, f1: 0.6337390026390948, Avg loss: 2.241447925567627 \n",
      "\n",
      "loss: 2.1927905082702637  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6270627062706271, Precision: 0.6401346408255648, recall: 0.630293223136331, f1: 0.6210199874243311, Avg loss: 2.2410480976104736 \n",
      "\n",
      "loss: 2.1927735805511475  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.5775577557755776, Precision: 0.6054343434343433, recall: 0.5816632485667674, f1: 0.5788480655395576, Avg loss: 2.2434915900230408 \n",
      "\n",
      "loss: 2.1928064823150635  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6072607260726073, Precision: 0.6320148024018992, recall: 0.6099951395773779, f1: 0.6047630589154904, Avg loss: 2.2416306138038635 \n",
      "\n",
      "loss: 2.1928396224975586  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.5841584158415841, Precision: 0.6051457902001379, recall: 0.5852264196853667, f1: 0.581285135619139, Avg loss: 2.2430678606033325 \n",
      "\n",
      "loss: 2.1926732063293457  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6204620462046204, Precision: 0.6448589580876553, recall: 0.6239731047354294, f1: 0.619037762877438, Avg loss: 2.24067485332489 \n",
      "\n",
      "loss: 2.192864418029785  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6006600660066007, Precision: 0.6070311236071394, recall: 0.5977743117954777, f1: 0.5921156119870618, Avg loss: 2.2412317991256714 \n",
      "\n",
      "loss: 2.192985773086548  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6171617161716172, Precision: 0.6363805249120816, recall: 0.6169990784612004, f1: 0.6133429073341687, Avg loss: 2.2397701144218445 \n",
      "\n",
      "loss: 2.1934731006622314  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.5808580858085809, Precision: 0.6026079538602909, recall: 0.5792988707829523, f1: 0.5782175750520449, Avg loss: 2.2389647364616394 \n",
      "\n",
      "loss: 2.1927568912506104  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.5973597359735974, Precision: 0.616376745909542, recall: 0.5918519793109264, f1: 0.5936537084422793, Avg loss: 2.2420886158943176 \n",
      "\n",
      "loss: 2.192923069000244  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.5907590759075908, Precision: 0.6167717351001919, recall: 0.5939025258612524, f1: 0.5893147991209178, Avg loss: 2.2406517267227173 \n",
      "\n",
      "loss: 2.1928393840789795  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.5577557755775577, Precision: 0.5692291443888398, recall: 0.5635151466499029, f1: 0.5515295254866661, Avg loss: 2.2427839040756226 \n",
      "\n",
      "loss: 2.192695140838623  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6237623762376238, Precision: 0.6455984509354075, recall: 0.6224793255889473, f1: 0.6205138953348711, Avg loss: 2.2376410365104675 \n",
      "\n",
      "loss: 2.1928088665008545  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6105610561056105, Precision: 0.6275371119349886, recall: 0.6084544885856289, f1: 0.6060519095840446, Avg loss: 2.241211712360382 \n",
      "\n",
      "loss: 2.1929399967193604  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.5676567656765676, Precision: 0.5870779149928086, recall: 0.5627445031344847, f1: 0.5652861562327163, Avg loss: 2.2393627762794495 \n",
      "\n",
      "loss: 2.192704916000366  [81.0/303]\n",
      "Test Error: \n",
      " Accuracy: 0.6072607260726073, Precision: 0.6121819795617028, recall: 0.6049281677124521, f1: 0.6023138306369908, Avg loss: 2.2406656742095947 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>▁▂▄▆▇▇▇██▇█▇████▇▇██▇▇▇▇▇██▇▇███▇▇▇▇▇▇█▇</td></tr><tr><td>Macro-f1-score</td><td>▁▂▄▆▇▇▇██▇█▇████▇▇███▇█▇▇██▇▇████▇▇▇▇▇██</td></tr><tr><td>Precision</td><td>▁▂▄▆▇▇▇█▇▇█████▇█▇██████████▇████▇▇▇█▇██</td></tr><tr><td>Recall</td><td>▁▂▄▆▇▇▇██▇█▇████▇▇███▇▇▇▇██▇▇████▇▇▇▇▇█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>0.60726</td></tr><tr><td>Macro-f1-score</td><td>0.60231</td></tr><tr><td>Precision</td><td>0.61218</td></tr><tr><td>Recall</td><td>0.60493</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wise-sweep-1</strong> at: <a href='https://wandb.ai/j-soberg/RNNs%20and%20You/runs/ep99j5i2' target=\"_blank\">https://wandb.ai/j-soberg/RNNs%20and%20You/runs/ep99j5i2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240419_074451-ep99j5i2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qpv4dws9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbow: countVector\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 37\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001635200503672175\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnetwork: ffnn\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnrows: 71\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 90\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\jespe\\git\\550dat\\prosjekt\\wandb\\run-20240419_074603-qpv4dws9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/j-soberg/RNNs%20and%20You/runs/qpv4dws9' target=\"_blank\">frosty-sweep-2</a></strong> to <a href='https://wandb.ai/j-soberg/RNNs%20and%20You' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/j-soberg/RNNs%20and%20You/sweeps/48m0nanw' target=\"_blank\">https://wandb.ai/j-soberg/RNNs%20and%20You/sweeps/48m0nanw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/j-soberg/RNNs%20and%20You' target=\"_blank\">https://wandb.ai/j-soberg/RNNs%20and%20You</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/j-soberg/RNNs%20and%20You/sweeps/48m0nanw' target=\"_blank\">https://wandb.ai/j-soberg/RNNs%20and%20You/sweeps/48m0nanw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/j-soberg/RNNs%20and%20You/runs/qpv4dws9' target=\"_blank\">https://wandb.ai/j-soberg/RNNs%20and%20You/runs/qpv4dws9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.30251407623291  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.38028169014084506, Precision: 0.4133333333333334, recall: 0.33585497835497835, f1: 0.3220417082917083, Avg loss: 2.294532219568888 \n",
      "\n",
      "loss: 2.1923317909240723  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.4084507042253521, Precision: 0.3335714285714285, recall: 0.3448701298701299, f1: 0.331893348197696, Avg loss: 2.239779313405355 \n",
      "\n",
      "loss: 2.0810163021087646  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.39436619718309857, Precision: 0.3566269841269841, recall: 0.38350649350649346, f1: 0.3511255411255411, Avg loss: 2.263838052749634 \n",
      "\n",
      "loss: 2.0337002277374268  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.38028169014084506, Precision: 0.3980555555555555, recall: 0.38040043290043285, f1: 0.35980142664353193, Avg loss: 2.2087533473968506 \n",
      "\n",
      "loss: 2.038227081298828  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.352112676056338, Precision: 0.37426739926739927, recall: 0.35388528138528136, f1: 0.3328105228105228, Avg loss: 2.2270348072052 \n",
      "\n",
      "loss: 2.033398151397705  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.36619718309859156, Precision: 0.4061255411255411, recall: 0.3588095238095238, f1: 0.3544537480063796, Avg loss: 2.1596304972966514 \n",
      "\n",
      "loss: 2.033442258834839  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.29577464788732394, Precision: 0.33974025974025973, recall: 0.29614718614718616, f1: 0.28593080895712475, Avg loss: 2.2061665852864585 \n",
      "\n",
      "loss: 2.065056085586548  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.323943661971831, Precision: 0.359010989010989, recall: 0.3070238095238095, f1: 0.3035209235209235, Avg loss: 2.1676597595214844 \n",
      "\n",
      "loss: 2.0345044136047363  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.323943661971831, Precision: 0.3697222222222222, recall: 0.33864718614718614, f1: 0.3189519252677147, Avg loss: 2.1610910097757974 \n",
      "\n",
      "loss: 2.034839630126953  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.38028169014084506, Precision: 0.4242024642024642, recall: 0.40202380952380956, f1: 0.37602092352092353, Avg loss: 2.2013673782348633 \n",
      "\n",
      "loss: 2.033836841583252  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.352112676056338, Precision: 0.38535714285714284, recall: 0.36043290043290044, f1: 0.34378787878787875, Avg loss: 2.2300665378570557 \n",
      "\n",
      "loss: 2.0646684169769287  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.28169014084507044, Precision: 0.35444444444444445, recall: 0.27955627705627706, f1: 0.2787032815825385, Avg loss: 2.234750429789225 \n",
      "\n",
      "loss: 2.03470516204834  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.30985915492957744, Precision: 0.34024891774891775, recall: 0.3339177489177489, f1: 0.31119047619047613, Avg loss: 2.198528607686361 \n",
      "\n",
      "loss: 2.0364270210266113  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.352112676056338, Precision: 0.39134615384615384, recall: 0.36043290043290044, f1: 0.33567714964773787, Avg loss: 2.1419746478398642 \n",
      "\n",
      "loss: 2.03515887260437  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.36619718309859156, Precision: 0.3845454545454545, recall: 0.39479437229437225, f1: 0.35782608258614446, Avg loss: 2.176677385965983 \n",
      "\n",
      "loss: 2.0663139820098877  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.38028169014084506, Precision: 0.3886324786324787, recall: 0.39971861471861475, f1: 0.3572124444183268, Avg loss: 2.228087902069092 \n",
      "\n",
      "loss: 2.0368707180023193  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.352112676056338, Precision: 0.3880952380952381, recall: 0.3445238095238095, f1: 0.3356739699928554, Avg loss: 2.1772330602010093 \n",
      "\n",
      "loss: 2.0658857822418213  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.36619718309859156, Precision: 0.388949938949939, recall: 0.3536147186147186, f1: 0.3440458887517711, Avg loss: 2.1848296324412027 \n",
      "\n",
      "loss: 2.066887617111206  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.38028169014084506, Precision: 0.37243145743145745, recall: 0.42293290043290044, f1: 0.3581649069884364, Avg loss: 2.2318855126698813 \n",
      "\n",
      "loss: 2.036360740661621  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.39436619718309857, Precision: 0.41818181818181815, recall: 0.41952380952380947, f1: 0.38247420020639833, Avg loss: 2.2219532330830893 \n",
      "\n",
      "loss: 2.03706693649292  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.38028169014084506, Precision: 0.42460317460317454, recall: 0.3945238095238095, f1: 0.37130862601450837, Avg loss: 2.2197877566019693 \n",
      "\n",
      "loss: 2.064800262451172  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.38028169014084506, Precision: 0.4144444444444444, recall: 0.4104329004329005, f1: 0.3654987659399424, Avg loss: 2.223849614461263 \n",
      "\n",
      "loss: 2.0659279823303223  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.3380281690140845, Precision: 0.4117857142857143, recall: 0.34614718614718615, f1: 0.34612460638776427, Avg loss: 2.2386205991109214 \n",
      "\n",
      "loss: 2.0371410846710205  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.30985915492957744, Precision: 0.35694444444444445, recall: 0.30872294372294373, f1: 0.29626247935071465, Avg loss: 2.230550209681193 \n",
      "\n",
      "loss: 2.0654218196868896  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.30985915492957744, Precision: 0.3557251082251082, recall: 0.31884199134199137, f1: 0.31021538918597746, Avg loss: 2.1974658171335855 \n",
      "\n",
      "loss: 2.065916061401367  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.352112676056338, Precision: 0.3966666666666666, recall: 0.38653679653679657, f1: 0.3478163992869875, Avg loss: 2.1952947775522866 \n",
      "\n",
      "loss: 2.036740303039551  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.352112676056338, Precision: 0.37666666666666665, recall: 0.3781277056277056, f1: 0.34485832794656324, Avg loss: 2.213167667388916 \n",
      "\n",
      "loss: 2.037585496902466  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.29577464788732394, Precision: 0.31595959595959594, recall: 0.3467640692640693, f1: 0.29618131868131864, Avg loss: 2.2044874827067056 \n",
      "\n",
      "loss: 2.0346407890319824  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.38028169014084506, Precision: 0.38511904761904764, recall: 0.3961147186147186, f1: 0.3727845194021665, Avg loss: 2.1923062801361084 \n",
      "\n",
      "loss: 2.0351946353912354  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.38028169014084506, Precision: 0.3880952380952381, recall: 0.3854004329004329, f1: 0.3659613915496268, Avg loss: 2.177307446797689 \n",
      "\n",
      "loss: 2.095487594604492  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.323943661971831, Precision: 0.32798701298701294, recall: 0.3227380952380952, f1: 0.308406309892378, Avg loss: 2.18839168548584 \n",
      "\n",
      "loss: 2.036689043045044  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.36619718309859156, Precision: 0.40561327561327565, recall: 0.3852380952380952, f1: 0.3582800034502821, Avg loss: 2.2293502489725747 \n",
      "\n",
      "loss: 2.036175489425659  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.323943661971831, Precision: 0.324029304029304, recall: 0.32254329004329, f1: 0.2991364191364191, Avg loss: 2.1326247453689575 \n",
      "\n",
      "loss: 2.0355546474456787  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.3380281690140845, Precision: 0.3663492063492063, recall: 0.37955627705627704, f1: 0.33243877037994685, Avg loss: 2.2005006472269693 \n",
      "\n",
      "loss: 2.036966323852539  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.29577464788732394, Precision: 0.3150865800865801, recall: 0.29936147186147183, f1: 0.27935508935508935, Avg loss: 2.2453859647115073 \n",
      "\n",
      "loss: 2.037583351135254  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.30985915492957744, Precision: 0.3711904761904762, recall: 0.3311796536796537, f1: 0.29607142857142854, Avg loss: 2.184919516245524 \n",
      "\n",
      "loss: 2.035679340362549  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.2676056338028169, Precision: 0.32234848484848483, recall: 0.28708874458874456, f1: 0.2569703335879806, Avg loss: 2.220121145248413 \n",
      "\n",
      "loss: 2.068108081817627  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.323943661971831, Precision: 0.31666666666666665, recall: 0.31273809523809526, f1: 0.28014770679732315, Avg loss: 2.180070718129476 \n",
      "\n",
      "loss: 2.0347211360931396  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.28169014084507044, Precision: 0.328989898989899, recall: 0.2690367965367965, f1: 0.25830810056816245, Avg loss: 2.1764045556386313 \n",
      "\n",
      "loss: 2.0665767192840576  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.28169014084507044, Precision: 0.28944444444444445, recall: 0.2638419913419913, f1: 0.2587352997879314, Avg loss: 2.256188948949178 \n",
      "\n",
      "loss: 2.067233085632324  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.28169014084507044, Precision: 0.2911111111111111, recall: 0.2586471861471861, f1: 0.2521221984070281, Avg loss: 2.230487664540609 \n",
      "\n",
      "loss: 2.0668978691101074  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.3380281690140845, Precision: 0.37857142857142856, recall: 0.3377380952380952, f1: 0.3198308554190907, Avg loss: 2.19694185256958 \n",
      "\n",
      "loss: 2.034403085708618  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.29577464788732394, Precision: 0.3144949494949495, recall: 0.31546536796536795, f1: 0.28684065934065933, Avg loss: 2.2648460070292153 \n",
      "\n",
      "loss: 2.0370283126831055  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.29577464788732394, Precision: 0.3529545454545454, recall: 0.3313744588744589, f1: 0.2868398268398268, Avg loss: 2.226217269897461 \n",
      "\n",
      "loss: 2.037074327468872  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.29577464788732394, Precision: 0.2986616161616162, recall: 0.30527056277056275, f1: 0.26638516969786313, Avg loss: 2.2088265419006348 \n",
      "\n",
      "loss: 2.0355257987976074  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.28169014084507044, Precision: 0.2914393939393939, recall: 0.3063744588744589, f1: 0.2650967161493477, Avg loss: 2.2512995402018228 \n",
      "\n",
      "loss: 2.036266803741455  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.29577464788732394, Precision: 0.2793528693528694, recall: 0.3149458874458874, f1: 0.2715208647561589, Avg loss: 2.221780856450399 \n",
      "\n",
      "loss: 2.035217523574829  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.23943661971830985, Precision: 0.27879329004329, recall: 0.25247835497835497, f1: 0.22550513212277917, Avg loss: 2.291165828704834 \n",
      "\n",
      "loss: 2.035055637359619  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.2535211267605634, Precision: 0.32614468864468865, recall: 0.27906926406926413, f1: 0.25557677616501145, Avg loss: 2.2299373149871826 \n",
      "\n",
      "loss: 2.033536672592163  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.30985915492957744, Precision: 0.33851190476190474, recall: 0.34585497835497836, f1: 0.2882168321874204, Avg loss: 2.2418824831644693 \n",
      "\n",
      "loss: 2.067845106124878  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.2535211267605634, Precision: 0.33474969474969474, recall: 0.2772835497835498, f1: 0.24765639589169003, Avg loss: 2.27360463142395 \n",
      "\n",
      "loss: 2.0357799530029297  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.28169014084507044, Precision: 0.2873917748917748, recall: 0.31676406926406925, f1: 0.26569757727652465, Avg loss: 2.2161248524983725 \n",
      "\n",
      "loss: 2.06659197807312  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.23943661971830985, Precision: 0.26766955266955267, recall: 0.28481601731601736, f1: 0.23200166190878263, Avg loss: 2.2446258862813315 \n",
      "\n",
      "loss: 2.0370230674743652  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.2676056338028169, Precision: 0.3240374331550802, recall: 0.28656926406926403, f1: 0.259994698284172, Avg loss: 2.2192296981811523 \n",
      "\n",
      "loss: 2.035879373550415  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.2676056338028169, Precision: 0.2823917748917749, recall: 0.29228354978354976, f1: 0.24372435098441292, Avg loss: 2.2360467116038003 \n",
      "\n",
      "loss: 2.035973072052002  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.23943661971830985, Precision: 0.2521825396825397, recall: 0.2633874458874459, f1: 0.2359247941600883, Avg loss: 2.243048906326294 \n",
      "\n",
      "loss: 2.037477970123291  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.28169014084507044, Precision: 0.29910256410256414, recall: 0.30997835497835496, f1: 0.2725085002716582, Avg loss: 2.219081163406372 \n",
      "\n",
      "loss: 2.035944938659668  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.2535211267605634, Precision: 0.3230769230769231, recall: 0.3041017316017316, f1: 0.2521328671328671, Avg loss: 2.250593980153402 \n",
      "\n",
      "loss: 2.0374414920806885  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.29577464788732394, Precision: 0.3393956043956044, recall: 0.3404978354978355, f1: 0.2750848824378236, Avg loss: 2.2081543604532876 \n",
      "\n",
      "loss: 2.0657827854156494  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.23943661971830985, Precision: 0.28057422969187673, recall: 0.28481601731601736, f1: 0.22106379255120673, Avg loss: 2.2549330393473306 \n",
      "\n",
      "loss: 2.0363664627075195  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.323943661971831, Precision: 0.36613719613719614, recall: 0.344556277056277, f1: 0.31207279562542717, Avg loss: 2.234391689300537 \n",
      "\n",
      "loss: 2.0352730751037598  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.2676056338028169, Precision: 0.2844155844155844, recall: 0.29228354978354976, f1: 0.25195413891234325, Avg loss: 2.205720822016398 \n",
      "\n",
      "loss: 2.0375194549560547  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.2676056338028169, Precision: 0.3211802902979373, recall: 0.3189069264069264, f1: 0.24205882352941172, Avg loss: 2.255526542663574 \n",
      "\n",
      "loss: 2.037471294403076  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.2535211267605634, Precision: 0.2617673992673993, recall: 0.31501082251082246, f1: 0.23758646582175996, Avg loss: 2.2787043253580728 \n",
      "\n",
      "loss: 2.0367379188537598  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.22535211267605634, Precision: 0.22650829562594268, recall: 0.25981601731601733, f1: 0.2033706816059757, Avg loss: 2.271963437398275 \n",
      "\n",
      "loss: 2.034273147583008  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.22535211267605634, Precision: 0.23333333333333334, recall: 0.27231601731601734, f1: 0.21234402852049908, Avg loss: 2.2945005098978677 \n",
      "\n",
      "loss: 2.0687255859375  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.23943661971830985, Precision: 0.2714102564102564, recall: 0.28481601731601736, f1: 0.220375694137304, Avg loss: 2.2125611305236816 \n",
      "\n",
      "loss: 2.0374674797058105  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.2112676056338028, Precision: 0.2411111111111111, recall: 0.2632251082251082, f1: 0.20357864357864358, Avg loss: 2.23599910736084 \n",
      "\n",
      "loss: 2.0401995182037354  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.23943661971830985, Precision: 0.2802465834818776, recall: 0.28481601731601736, f1: 0.22941305770253137, Avg loss: 2.2690075238545737 \n",
      "\n",
      "loss: 2.0362799167633057  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.23943661971830985, Precision: 0.2632905982905983, recall: 0.30072510822510823, f1: 0.233975468975469, Avg loss: 2.252713918685913 \n",
      "\n",
      "loss: 2.0367228984832764  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.23943661971830985, Precision: 0.31576923076923075, recall: 0.2689069264069264, f1: 0.23142857142857146, Avg loss: 2.2803467909495034 \n",
      "\n",
      "loss: 2.0677707195281982  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.18309859154929578, Precision: 0.2764285714285714, recall: 0.22913419913419913, f1: 0.16961319966583124, Avg loss: 2.2685186862945557 \n",
      "\n",
      "loss: 2.040339708328247  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.22535211267605634, Precision: 0.2529164313946922, recall: 0.25981601731601733, f1: 0.21120370370370373, Avg loss: 2.2342305978139243 \n",
      "\n",
      "loss: 2.0666372776031494  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.2112676056338028, Precision: 0.2092207792207792, recall: 0.23462121212121212, f1: 0.18230325814536338, Avg loss: 2.2421693801879883 \n",
      "\n",
      "loss: 2.037304639816284  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.23943661971830985, Precision: 0.26987179487179486, recall: 0.2564069264069264, f1: 0.20865079365079361, Avg loss: 2.325898011525472 \n",
      "\n",
      "loss: 2.035072088241577  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.23943661971830985, Precision: 0.2771328671328671, recall: 0.2564069264069264, f1: 0.21239938080495352, Avg loss: 2.2805471420288086 \n",
      "\n",
      "loss: 2.0651628971099854  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.22535211267605634, Precision: 0.26528471528471526, recall: 0.25462121212121214, f1: 0.184816963222536, Avg loss: 2.2528703212738037 \n",
      "\n",
      "loss: 2.035919189453125  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.23943661971830985, Precision: 0.320479375696767, recall: 0.27231601731601734, f1: 0.20410256410256408, Avg loss: 2.2810521920522056 \n",
      "\n",
      "loss: 2.0651395320892334  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.2112676056338028, Precision: 0.3236363636363636, recall: 0.2323160173160173, f1: 0.19884615384615384, Avg loss: 2.2275781631469727 \n",
      "\n",
      "loss: 2.066842794418335  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.18309859154929578, Precision: 0.25614219114219117, recall: 0.21303030303030304, f1: 0.16838827838827838, Avg loss: 2.295705795288086 \n",
      "\n",
      "loss: 2.0367558002471924  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.18309859154929578, Precision: 0.2749206349206349, recall: 0.19640692640692642, f1: 0.17417433443749236, Avg loss: 2.307490666707357 \n",
      "\n",
      "loss: 2.0374221801757812  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.18309859154929578, Precision: 0.19611111111111112, recall: 0.19462121212121214, f1: 0.15794733044733042, Avg loss: 2.2410081227620444 \n",
      "\n",
      "loss: 2.0650501251220703  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.16901408450704225, Precision: 0.27819444444444447, recall: 0.17981601731601732, f1: 0.15569947596263384, Avg loss: 2.257918039957682 \n",
      "\n",
      "loss: 2.0672736167907715  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.18309859154929578, Precision: 0.321265664160401, recall: 0.1998160173160173, f1: 0.16960472530266582, Avg loss: 2.277155637741089 \n",
      "\n",
      "loss: 2.066500186920166  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.16901408450704225, Precision: 0.22361111111111112, recall: 0.17303030303030303, f1: 0.14505494505494504, Avg loss: 2.275123675664266 \n",
      "\n",
      "loss: 2.0374324321746826  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.2535211267605634, Precision: 0.38, recall: 0.2914069264069264, f1: 0.25521564315345446, Avg loss: 2.2474587758382163 \n",
      "\n",
      "loss: 2.035209894180298  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.23943661971830985, Precision: 0.27077485380116956, recall: 0.2771212121212121, f1: 0.22032511835143415, Avg loss: 2.2725777626037598 \n",
      "\n",
      "loss: 2.0660927295684814  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.19718309859154928, Precision: 0.18748832866479925, recall: 0.23393939393939395, f1: 0.17051393051393055, Avg loss: 2.1916371981302896 \n",
      "\n",
      "loss: 2.03560733795166  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.19718309859154928, Precision: 0.34617918313570484, recall: 0.23893939393939392, f1: 0.18446446027091187, Avg loss: 2.1708237330118814 \n",
      "\n",
      "loss: 2.0681405067443848  [32.0/71]\n",
      "Test Error: \n",
      " Accuracy: 0.1267605633802817, Precision: 0.11255411255411255, recall: 0.14393939393939395, f1: 0.1088888888888889, Avg loss: 2.278881788253784 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>██▇▅█▅▇███▇▇▅█▇▅▅▅▇▅▅▄▄▄▅▄▄▅▄▄▄▄▃▄▄▂▂▂▄▁</td></tr><tr><td>Macro-f1-score</td><td>▇▇▇▆█▅▇███▇▇▆██▅▅▅▇▆▅▄▅▄▅▅▄▅▄▄▄▄▃▄▃▃▂▂▄▁</td></tr><tr><td>Precision</td><td>█▆▇▆█▆▇▇▇██▇▆▇█▆▆▆▇▆▅▅▆▄▅▆▅▅▄▅▅▆▃▅▆▄▅▃▅▁</td></tr><tr><td>Recall</td><td>▆▇▆▅▇▄▆▇█▇▆▇▆▇▇▅▅▄▆▆▅▄▄▅▅▅▅▅▅▅▅▄▃▄▄▃▂▂▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>0.12676</td></tr><tr><td>Macro-f1-score</td><td>0.10889</td></tr><tr><td>Precision</td><td>0.11255</td></tr><tr><td>Recall</td><td>0.14394</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">frosty-sweep-2</strong> at: <a href='https://wandb.ai/j-soberg/RNNs%20and%20You/runs/qpv4dws9' target=\"_blank\">https://wandb.ai/j-soberg/RNNs%20and%20You/runs/qpv4dws9</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240419_074603-qpv4dws9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1k21e5iq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 73\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbow: tf_idf\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 185\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0022132657615738637\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnetwork: rnn\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnrows: 324\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 59\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\jespe\\git\\550dat\\prosjekt\\wandb\\run-20240419_074654-1k21e5iq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/j-soberg/RNNs%20and%20You/runs/1k21e5iq' target=\"_blank\">cerulean-sweep-3</a></strong> to <a href='https://wandb.ai/j-soberg/RNNs%20and%20You' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/j-soberg/RNNs%20and%20You/sweeps/48m0nanw' target=\"_blank\">https://wandb.ai/j-soberg/RNNs%20and%20You/sweeps/48m0nanw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/j-soberg/RNNs%20and%20You' target=\"_blank\">https://wandb.ai/j-soberg/RNNs%20and%20You</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/j-soberg/RNNs%20and%20You/sweeps/48m0nanw' target=\"_blank\">https://wandb.ai/j-soberg/RNNs%20and%20You/sweeps/48m0nanw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/j-soberg/RNNs%20and%20You/runs/1k21e5iq' target=\"_blank\">https://wandb.ai/j-soberg/RNNs%20and%20You/runs/1k21e5iq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7847\n",
      "loss: 2.302605628967285  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.4104938271604938, Precision: 0.3979120939856863, recall: 0.40185134813435386, f1: 0.3898200670640054, Avg loss: 2.301769828796387 \n",
      "\n",
      "loss: 2.3007869720458984  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.5432098765432098, Precision: 0.5185578706262384, recall: 0.5395302727578475, f1: 0.5085662386459489, Avg loss: 2.3008939266204833 \n",
      "\n",
      "loss: 2.2981488704681396  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.5833333333333334, Precision: 0.5572945363460069, recall: 0.5718552593198113, f1: 0.5527107772660034, Avg loss: 2.2996124267578124 \n",
      "\n",
      "loss: 2.2939987182617188  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6172839506172839, Precision: 0.6163535100875255, recall: 0.6197591126038822, f1: 0.5937830865010316, Avg loss: 2.2979050636291505 \n",
      "\n",
      "loss: 2.2883946895599365  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6049382716049383, Precision: 0.5842202681209719, recall: 0.5995165374928861, f1: 0.5710520494026484, Avg loss: 2.2951509952545166 \n",
      "\n",
      "loss: 2.280033826828003  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.5524691358024691, Precision: 0.530861316071144, recall: 0.5461264022045966, f1: 0.5199777589866155, Avg loss: 2.2918421745300295 \n",
      "\n",
      "loss: 2.2696027755737305  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.45987654320987653, Precision: 0.4537913339550427, recall: 0.44914542836742316, f1: 0.4391655616522151, Avg loss: 2.287959098815918 \n",
      "\n",
      "loss: 2.2541768550872803  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.5462962962962963, Precision: 0.5395119334304187, recall: 0.5354694036993531, f1: 0.5247492415044469, Avg loss: 2.2820852279663084 \n",
      "\n",
      "loss: 2.2323217391967773  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.5123456790123457, Precision: 0.5041887302947925, recall: 0.507716949918286, f1: 0.4969714532618725, Avg loss: 2.275697135925293 \n",
      "\n",
      "loss: 2.224010467529297  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.5740740740740741, Precision: 0.5750508571249673, recall: 0.58422398080065, f1: 0.5666764350359196, Avg loss: 2.268809127807617 \n",
      "\n",
      "loss: 2.209336757659912  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.5802469135802469, Precision: 0.5730900104797163, recall: 0.5800059846940566, f1: 0.5677866418744658, Avg loss: 2.265497398376465 \n",
      "\n",
      "loss: 2.199218273162842  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6141975308641975, Precision: 0.6124565388272285, recall: 0.6133800316392316, f1: 0.6023213711081256, Avg loss: 2.2598845958709717 \n",
      "\n",
      "loss: 2.199906349182129  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6450617283950617, Precision: 0.6372286094291753, recall: 0.6456526287702679, f1: 0.6316475921299565, Avg loss: 2.2480633735656737 \n",
      "\n",
      "loss: 2.1879162788391113  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6450617283950617, Precision: 0.64279093786263, recall: 0.6448972569370686, f1: 0.6354836096506535, Avg loss: 2.2475022792816164 \n",
      "\n",
      "loss: 2.185598850250244  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6574074074074074, Precision: 0.6615418589283815, recall: 0.6624766913564458, f1: 0.6534983186438463, Avg loss: 2.2457640171051025 \n",
      "\n",
      "loss: 2.185133457183838  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6388888888888888, Precision: 0.6348554147465438, recall: 0.6352472698452928, f1: 0.6279350527856973, Avg loss: 2.2428987503051756 \n",
      "\n",
      "loss: 2.1835403442382812  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6296296296296297, Precision: 0.6279986105113983, recall: 0.6316823233206984, f1: 0.6210229726331421, Avg loss: 2.243482542037964 \n",
      "\n",
      "loss: 2.1836886405944824  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6574074074074074, Precision: 0.6571540452338562, recall: 0.6551589513667746, f1: 0.6478312195391658, Avg loss: 2.231500434875488 \n",
      "\n",
      "loss: 2.1826109886169434  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6141975308641975, Precision: 0.6202240398776777, recall: 0.6223309523159698, f1: 0.608763082404005, Avg loss: 2.234468460083008 \n",
      "\n",
      "loss: 2.1830575466156006  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6080246913580247, Precision: 0.6072000121980772, recall: 0.6047889502307581, f1: 0.5979114160126551, Avg loss: 2.231485366821289 \n",
      "\n",
      "loss: 2.1824467182159424  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6450617283950617, Precision: 0.6527883239816724, recall: 0.6485586680700014, f1: 0.6419958154252973, Avg loss: 2.23332200050354 \n",
      "\n",
      "loss: 2.1829042434692383  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6203703703703703, Precision: 0.6307810162460129, recall: 0.6210205922115989, f1: 0.6186371421609432, Avg loss: 2.2321954727172852 \n",
      "\n",
      "loss: 2.182770013809204  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6512345679012346, Precision: 0.6453233594125434, recall: 0.648919550595961, f1: 0.6415600672583849, Avg loss: 2.2327620506286623 \n",
      "\n",
      "loss: 2.1824584007263184  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6481481481481481, Precision: 0.6542583156240143, recall: 0.6486279443973385, f1: 0.6416494384237068, Avg loss: 2.231656312942505 \n",
      "\n",
      "loss: 2.182626962661743  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6327160493827161, Precision: 0.6324084077366809, recall: 0.6413185822386115, f1: 0.6271097253949026, Avg loss: 2.233639621734619 \n",
      "\n",
      "loss: 2.1823365688323975  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6574074074074074, Precision: 0.6604495369266805, recall: 0.659364677809903, f1: 0.6483327486255315, Avg loss: 2.2263500690460205 \n",
      "\n",
      "loss: 2.182356834411621  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6759259259259259, Precision: 0.6781394576622505, recall: 0.6800830332925363, f1: 0.6723863415473585, Avg loss: 2.2242616176605225 \n",
      "\n",
      "loss: 2.182033061981201  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6265432098765432, Precision: 0.6417100195718616, recall: 0.6311561654294018, f1: 0.6198798556210506, Avg loss: 2.2319396495819093 \n",
      "\n",
      "loss: 2.1821110248565674  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6697530864197531, Precision: 0.6824959274655016, recall: 0.6725273584849404, f1: 0.6686344692163614, Avg loss: 2.2270750522613527 \n",
      "\n",
      "loss: 2.1819632053375244  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6080246913580247, Precision: 0.625801688327076, recall: 0.6152255834697816, f1: 0.6090168795350553, Avg loss: 2.2290850639343263 \n",
      "\n",
      "loss: 2.181918144226074  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6296296296296297, Precision: 0.6363743604378451, recall: 0.6339476235776194, f1: 0.6252445529618889, Avg loss: 2.224129056930542 \n",
      "\n",
      "loss: 2.1822643280029297  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6234567901234568, Precision: 0.6380016695742465, recall: 0.6301467714559579, f1: 0.623042938502065, Avg loss: 2.2275962829589844 \n",
      "\n",
      "loss: 2.1822292804718018  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6172839506172839, Precision: 0.6343354524554482, recall: 0.6237934753075309, f1: 0.6130132040439775, Avg loss: 2.2263949394226072 \n",
      "\n",
      "loss: 2.1820871829986572  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6080246913580247, Precision: 0.6153178670394812, recall: 0.6078345748132403, f1: 0.600778712534602, Avg loss: 2.2327038764953615 \n",
      "\n",
      "loss: 2.181795358657837  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.654320987654321, Precision: 0.6694210941061264, recall: 0.6599988789967359, f1: 0.647434368408503, Avg loss: 2.2256021022796633 \n",
      "\n",
      "loss: 2.181767463684082  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6604938271604939, Precision: 0.6698334411503988, recall: 0.6723838573906535, f1: 0.6581117642499952, Avg loss: 2.220591974258423 \n",
      "\n",
      "loss: 2.1823036670684814  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6172839506172839, Precision: 0.621243550996393, recall: 0.6189833094458534, f1: 0.6131367673239213, Avg loss: 2.2264226913452148 \n",
      "\n",
      "loss: 2.18186354637146  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6296296296296297, Precision: 0.6485730823154758, recall: 0.6388946471052699, f1: 0.6273145120441014, Avg loss: 2.2242871284484864 \n",
      "\n",
      "loss: 2.1832478046417236  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6203703703703703, Precision: 0.6352582060410288, recall: 0.6163175855421674, f1: 0.6156449079798294, Avg loss: 2.2229225635528564 \n",
      "\n",
      "loss: 2.181994676589966  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6512345679012346, Precision: 0.6587023181372151, recall: 0.6584598932410841, f1: 0.6473452091568295, Avg loss: 2.215488910675049 \n",
      "\n",
      "loss: 2.1819891929626465  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6481481481481481, Precision: 0.6674835002414538, recall: 0.6557887491763229, f1: 0.6478691311319263, Avg loss: 2.214041519165039 \n",
      "\n",
      "loss: 2.181795597076416  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6419753086419753, Precision: 0.6526622264550344, recall: 0.640398794524813, f1: 0.6360652779541636, Avg loss: 2.22080078125 \n",
      "\n",
      "loss: 2.1818771362304688  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6296296296296297, Precision: 0.6409839964598559, recall: 0.6364388460430859, f1: 0.626544129544269, Avg loss: 2.2236722469329835 \n",
      "\n",
      "loss: 2.1814980506896973  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6450617283950617, Precision: 0.6661462818733941, recall: 0.6504036390207955, f1: 0.644528429830825, Avg loss: 2.220248556137085 \n",
      "\n",
      "loss: 2.181466817855835  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.654320987654321, Precision: 0.6591986099598726, recall: 0.6590697728061516, f1: 0.6501125166803516, Avg loss: 2.223744440078735 \n",
      "\n",
      "loss: 2.1812868118286133  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6450617283950617, Precision: 0.6626613353121973, recall: 0.6494899247996712, f1: 0.6417594525701507, Avg loss: 2.217136335372925 \n",
      "\n",
      "loss: 2.1809818744659424  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6604938271604939, Precision: 0.6829396070822218, recall: 0.6680234133690326, f1: 0.6578629931307858, Avg loss: 2.22178111076355 \n",
      "\n",
      "loss: 2.1819686889648438  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6203703703703703, Precision: 0.6448942723657252, recall: 0.6238816961903227, f1: 0.6173041455807218, Avg loss: 2.2180597305297853 \n",
      "\n",
      "loss: 2.181490898132324  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6265432098765432, Precision: 0.6504626470290072, recall: 0.6379831065430942, f1: 0.6268026377184261, Avg loss: 2.2209065437316893 \n",
      "\n",
      "loss: 2.1815192699432373  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6327160493827161, Precision: 0.6585766525472408, recall: 0.6404631201530843, f1: 0.6327525443671275, Avg loss: 2.2262986660003663 \n",
      "\n",
      "loss: 2.181170701980591  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6450617283950617, Precision: 0.6511951743716076, recall: 0.6479875789865557, f1: 0.6403789529644243, Avg loss: 2.2259976387023928 \n",
      "\n",
      "loss: 2.181337356567383  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6265432098765432, Precision: 0.6371896178347791, recall: 0.6325197111127141, f1: 0.6223255479969256, Avg loss: 2.221521425247192 \n",
      "\n",
      "loss: 2.1816933155059814  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6450617283950617, Precision: 0.6512124901905991, recall: 0.650491571182018, f1: 0.6385094575812855, Avg loss: 2.219432735443115 \n",
      "\n",
      "loss: 2.181175708770752  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6574074074074074, Precision: 0.6684756431308155, recall: 0.6656560428022373, f1: 0.655342072677454, Avg loss: 2.217940330505371 \n",
      "\n",
      "loss: 2.1814680099487305  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6604938271604939, Precision: 0.6626049713409334, recall: 0.6654932925040659, f1: 0.6552373593032951, Avg loss: 2.2239677906036377 \n",
      "\n",
      "loss: 2.181109666824341  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6450617283950617, Precision: 0.6584456888557428, recall: 0.648848571723229, f1: 0.6370424893225942, Avg loss: 2.2232340812683105 \n",
      "\n",
      "loss: 2.1810989379882812  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6450617283950617, Precision: 0.6596759744412246, recall: 0.6539280871930213, f1: 0.6450415331581574, Avg loss: 2.2190813064575194 \n",
      "\n",
      "loss: 2.18078351020813  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6697530864197531, Precision: 0.6764876870379428, recall: 0.6693724078630053, f1: 0.6629842906828773, Avg loss: 2.2154669761657715 \n",
      "\n",
      "loss: 2.1815927028656006  [73.0/324]\n",
      "Test Error: \n",
      " Accuracy: 0.6296296296296297, Precision: 0.6556784006368921, recall: 0.6357354496302831, f1: 0.6275728447061566, Avg loss: 2.220824861526489 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>▁▄▆▆▅▅▄▅▆▇█▇█▆▇▇▇███▆▇▆▇█▇▇▇▇▇▇█▇▇▇▇█▇▇▇</td></tr><tr><td>Macro-f1-score</td><td>▁▄▅▅▄▄▄▅▆▇█▇▇▆▇▇▇▇██▆▇▇▇█▇▇▇▇▇▇█▇▇▇▇█▇▇▇</td></tr><tr><td>Precision</td><td>▁▄▅▆▄▄▄▅▆▇▇▇▇▆▇▇▇▇██▇▇▇██▇▇█▇█▇█▇▇▇▇█▇▇▇</td></tr><tr><td>Recall</td><td>▁▄▅▆▅▄▄▅▆▇█▇▇▆▇▇▇▇██▆▇▇▇█▇▆▇▇▇▇█▇▇▇▇█▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>0.62963</td></tr><tr><td>Macro-f1-score</td><td>0.62757</td></tr><tr><td>Precision</td><td>0.65568</td></tr><tr><td>Recall</td><td>0.63574</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cerulean-sweep-3</strong> at: <a href='https://wandb.ai/j-soberg/RNNs%20and%20You/runs/1k21e5iq' target=\"_blank\">https://wandb.ai/j-soberg/RNNs%20and%20You/runs/1k21e5iq</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240419_074654-1k21e5iq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lstl8tp5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 109\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbow: tf_idf\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005115966692873987\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnetwork: rnn\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnrows: 260\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 51\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\jespe\\git\\550dat\\prosjekt\\wandb\\run-20240419_074802-lstl8tp5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/j-soberg/RNNs%20and%20You/runs/lstl8tp5' target=\"_blank\">dulcet-sweep-4</a></strong> to <a href='https://wandb.ai/j-soberg/RNNs%20and%20You' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/j-soberg/RNNs%20and%20You/sweeps/48m0nanw' target=\"_blank\">https://wandb.ai/j-soberg/RNNs%20and%20You/sweeps/48m0nanw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/j-soberg/RNNs%20and%20You' target=\"_blank\">https://wandb.ai/j-soberg/RNNs%20and%20You</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/j-soberg/RNNs%20and%20You/sweeps/48m0nanw' target=\"_blank\">https://wandb.ai/j-soberg/RNNs%20and%20You/sweeps/48m0nanw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/j-soberg/RNNs%20and%20You/runs/lstl8tp5' target=\"_blank\">https://wandb.ai/j-soberg/RNNs%20and%20You/runs/lstl8tp5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6842\n",
      "loss: 2.302616596221924  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.08461538461538462, Precision: 0.08704895866660572, recall: 0.09232142911563264, f1: 0.08734199391965725, Avg loss: 2.3023858865102134 \n",
      "\n",
      "loss: 2.3026037216186523  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.13076923076923078, Precision: 0.13523842391362675, recall: 0.13936943086764153, f1: 0.13053669994178266, Avg loss: 2.302467664082845 \n",
      "\n",
      "loss: 2.3025028705596924  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.13846153846153847, Precision: 0.147563915553046, recall: 0.14571059005631812, f1: 0.14102909758385077, Avg loss: 2.3024418354034424 \n",
      "\n",
      "loss: 2.3024191856384277  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.12692307692307692, Precision: 0.13728865687689212, recall: 0.13609115734842964, f1: 0.13209383814205386, Avg loss: 2.3024868965148926 \n",
      "\n",
      "loss: 2.3022987842559814  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.13846153846153847, Precision: 0.1451169472023534, recall: 0.14651028468315802, f1: 0.1388062683883132, Avg loss: 2.3023505210876465 \n",
      "\n",
      "loss: 2.302246570587158  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.15, Precision: 0.15688004080094622, recall: 0.1579766813281604, f1: 0.1480545993449541, Avg loss: 2.302243789037069 \n",
      "\n",
      "loss: 2.302215814590454  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.1423076923076923, Precision: 0.15643152055912854, recall: 0.1509669743418937, f1: 0.14570992802083488, Avg loss: 2.302381753921509 \n",
      "\n",
      "loss: 2.3020615577697754  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.15384615384615385, Precision: 0.15849887554767977, recall: 0.1604581681389346, f1: 0.1555686921773878, Avg loss: 2.302241245905558 \n",
      "\n",
      "loss: 2.301990270614624  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.14615384615384616, Precision: 0.15822965742054027, recall: 0.1479268079629385, f1: 0.14673146655037558, Avg loss: 2.302450100580851 \n",
      "\n",
      "loss: 2.3019919395446777  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.1423076923076923, Precision: 0.15367791321738689, recall: 0.15243135445130424, f1: 0.14377530238248917, Avg loss: 2.3022031784057617 \n",
      "\n",
      "loss: 2.3018479347229004  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.1423076923076923, Precision: 0.14262422360248447, recall: 0.16058108857195383, f1: 0.14257376861815624, Avg loss: 2.302122195561727 \n",
      "\n",
      "loss: 2.3019161224365234  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.13076923076923078, Precision: 0.1442487212276215, recall: 0.13244029988008155, f1: 0.1318275380706404, Avg loss: 2.3022647698720298 \n",
      "\n",
      "loss: 2.301725149154663  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.13846153846153847, Precision: 0.14334099136730716, recall: 0.15885028055444086, f1: 0.14390607148492057, Avg loss: 2.302175760269165 \n",
      "\n",
      "loss: 2.301704168319702  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.2, Precision: 0.2108369599901858, recall: 0.20507617783190213, f1: 0.19857264331016392, Avg loss: 2.302217721939087 \n",
      "\n",
      "loss: 2.301597833633423  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.2, Precision: 0.22451352642470396, recall: 0.2081841925458136, f1: 0.20143319158214035, Avg loss: 2.301948308944702 \n",
      "\n",
      "loss: 2.30149245262146  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.2230769230769231, Precision: 0.22715083120377272, recall: 0.23593991914822215, f1: 0.22522770761328367, Avg loss: 2.3021415869394937 \n",
      "\n",
      "loss: 2.3014893531799316  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.18076923076923077, Precision: 0.20237835108594285, recall: 0.18741324468640996, f1: 0.1841015625619254, Avg loss: 2.3020873069763184 \n",
      "\n",
      "loss: 2.301339626312256  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.23461538461538461, Precision: 0.24990160710748946, recall: 0.24822825954505623, f1: 0.23196464332451727, Avg loss: 2.301885445912679 \n",
      "\n",
      "loss: 2.3013756275177  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.19615384615384615, Precision: 0.20562323645466757, recall: 0.2035716251077951, f1: 0.19821031930699484, Avg loss: 2.3018526236216226 \n",
      "\n",
      "loss: 2.3013131618499756  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.23076923076923078, Precision: 0.24044097996590788, recall: 0.2382268143534012, f1: 0.22731442988555006, Avg loss: 2.3017497857411704 \n",
      "\n",
      "loss: 2.3011977672576904  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.25769230769230766, Precision: 0.2563907959293355, recall: 0.26713316688123706, f1: 0.25361311566845635, Avg loss: 2.301905552546183 \n",
      "\n",
      "loss: 2.300976037979126  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.2153846153846154, Precision: 0.22463480963480964, recall: 0.22681441210157657, f1: 0.2130425482632356, Avg loss: 2.3016406695048013 \n",
      "\n",
      "loss: 2.300846576690674  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.2846153846153846, Precision: 0.2951662873530867, recall: 0.29864306462023704, f1: 0.2810341049224399, Avg loss: 2.30177640914917 \n",
      "\n",
      "loss: 2.300727367401123  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.24615384615384617, Precision: 0.25022261407175195, recall: 0.2599714109546221, f1: 0.24546017385160188, Avg loss: 2.3015263080596924 \n",
      "\n",
      "loss: 2.3006298542022705  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.26153846153846155, Precision: 0.26420152901159766, recall: 0.26974202991383567, f1: 0.25757750417612285, Avg loss: 2.301722844441732 \n",
      "\n",
      "loss: 2.300698757171631  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.2692307692307692, Precision: 0.2734866201943559, recall: 0.275249489899951, f1: 0.2642330875053761, Avg loss: 2.301585833231608 \n",
      "\n",
      "loss: 2.3005146980285645  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.24615384615384617, Precision: 0.24466522720199188, recall: 0.25818165539615034, f1: 0.2420488596019102, Avg loss: 2.301786740620931 \n",
      "\n",
      "loss: 2.300215005874634  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.28846153846153844, Precision: 0.29123924105327414, recall: 0.3003403349455772, f1: 0.2830098023099143, Avg loss: 2.3015854358673096 \n",
      "\n",
      "loss: 2.3002099990844727  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.25769230769230766, Precision: 0.2687125036020548, recall: 0.2512853756065958, f1: 0.2500010790088628, Avg loss: 2.3015477657318115 \n",
      "\n",
      "loss: 2.300072431564331  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.3192307692307692, Precision: 0.3275769600769601, recall: 0.3227422443201891, f1: 0.3146172329510097, Avg loss: 2.3013157844543457 \n",
      "\n",
      "loss: 2.3000664710998535  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.29615384615384616, Precision: 0.3100695987849618, recall: 0.3022581817262867, f1: 0.29247003066857574, Avg loss: 2.301424423853556 \n",
      "\n",
      "loss: 2.3000428676605225  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.27307692307692305, Precision: 0.28101571334148595, recall: 0.27980059074506275, f1: 0.269796507685155, Avg loss: 2.301417509714762 \n",
      "\n",
      "loss: 2.2998275756835938  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.3730769230769231, Precision: 0.3818386672844181, recall: 0.3834866205137416, f1: 0.36775435401260786, Avg loss: 2.301268736521403 \n",
      "\n",
      "loss: 2.2995336055755615  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.3153846153846154, Precision: 0.3037168089335272, recall: 0.32422688355606416, f1: 0.29469591124753924, Avg loss: 2.301377455393473 \n",
      "\n",
      "loss: 2.2995107173919678  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.34615384615384615, Precision: 0.36230089769092333, recall: 0.3556707444195155, f1: 0.3389491136502986, Avg loss: 2.301096280415853 \n",
      "\n",
      "loss: 2.2991714477539062  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.3384615384615385, Precision: 0.34775780572050297, recall: 0.3436498725025328, f1: 0.3293922393461769, Avg loss: 2.301293055216471 \n",
      "\n",
      "loss: 2.2990808486938477  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.34615384615384615, Precision: 0.3514344865032021, recall: 0.35324329494882917, f1: 0.33685793866648217, Avg loss: 2.3012377421061196 \n",
      "\n",
      "loss: 2.2989039421081543  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.33076923076923076, Precision: 0.33442318755879663, recall: 0.3370568656941817, f1: 0.31922863215842484, Avg loss: 2.3011484940846763 \n",
      "\n",
      "loss: 2.298769474029541  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.36153846153846153, Precision: 0.36730818462130127, recall: 0.3641714439712314, f1: 0.3518660075670086, Avg loss: 2.301088333129883 \n",
      "\n",
      "loss: 2.298736572265625  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.3576923076923077, Precision: 0.35758274418537306, recall: 0.36490686929731486, f1: 0.34229413085179267, Avg loss: 2.3009372552235923 \n",
      "\n",
      "loss: 2.298384428024292  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.3769230769230769, Precision: 0.3870705782933908, recall: 0.3844087138342828, f1: 0.3663053171023255, Avg loss: 2.3009425004323325 \n",
      "\n",
      "loss: 2.2979891300201416  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.36923076923076925, Precision: 0.38841358164887574, recall: 0.379913665364522, f1: 0.3652676909627387, Avg loss: 2.3007640838623047 \n",
      "\n",
      "loss: 2.2982611656188965  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.38076923076923075, Precision: 0.38386183693139153, recall: 0.3859233807432525, f1: 0.36605702325869666, Avg loss: 2.30080509185791 \n",
      "\n",
      "loss: 2.297847270965576  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.3730769230769231, Precision: 0.3759157509157509, recall: 0.3699976179468198, f1: 0.3600415788935476, Avg loss: 2.30059814453125 \n",
      "\n",
      "loss: 2.2978107929229736  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.4269230769230769, Precision: 0.41269231090854436, recall: 0.4348974386059621, f1: 0.4048398405639507, Avg loss: 2.3003247578938804 \n",
      "\n",
      "loss: 2.297578811645508  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.3923076923076923, Precision: 0.3938093975660254, recall: 0.39411536290209337, f1: 0.37823522460336184, Avg loss: 2.300436496734619 \n",
      "\n",
      "loss: 2.2972140312194824  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.4, Precision: 0.3984048356184579, recall: 0.4153355034650795, f1: 0.3839026761252805, Avg loss: 2.3004304567972818 \n",
      "\n",
      "loss: 2.2971606254577637  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.38076923076923075, Precision: 0.3780898901467955, recall: 0.38967177898994965, f1: 0.36725846366979564, Avg loss: 2.3001152674357095 \n",
      "\n",
      "loss: 2.2969682216644287  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.4230769230769231, Precision: 0.41718010059836247, recall: 0.4212383252036614, f1: 0.4009781188355911, Avg loss: 2.299983580907186 \n",
      "\n",
      "loss: 2.2965190410614014  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.4576923076923077, Precision: 0.44882745771600263, recall: 0.466804120033988, f1: 0.43734369980044085, Avg loss: 2.2996651331583657 \n",
      "\n",
      "loss: 2.2964670658111572  [109.0/260]\n",
      "Test Error: \n",
      " Accuracy: 0.46153846153846156, Precision: 0.4555752059617766, recall: 0.46297699944473764, f1: 0.43904689276241005, Avg loss: 2.2999958197275796 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>▁▂▂▂▂▂▂▂▂▂▂▃▄▃▄▄▄▃▄▄▄▄▄▅▅▆▅▆▆▆▆▆▆▆▆▇▇▆▇█</td></tr><tr><td>Macro-f1-score</td><td>▁▂▂▂▂▂▂▂▂▂▂▃▄▃▄▄▄▄▄▄▅▄▄▆▅▇▅▆▆▆▆▆▇▇▆▇▇▇▇█</td></tr><tr><td>Precision</td><td>▁▂▂▂▂▂▂▂▂▂▂▄▄▃▄▄▄▄▄▄▅▄▄▆▅▇▅▆▆▆▆▆▇▇▆▇▇▇▇█</td></tr><tr><td>Recall</td><td>▁▂▂▂▂▂▂▂▂▂▂▃▄▃▄▄▄▄▄▄▄▄▄▅▅▆▅▆▆▆▆▆▆▇▆▇▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>0.46154</td></tr><tr><td>Macro-f1-score</td><td>0.43905</td></tr><tr><td>Precision</td><td>0.45558</td></tr><tr><td>Recall</td><td>0.46298</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dulcet-sweep-4</strong> at: <a href='https://wandb.ai/j-soberg/RNNs%20and%20You/runs/lstl8tp5' target=\"_blank\">https://wandb.ai/j-soberg/RNNs%20and%20You/runs/lstl8tp5</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240419_074802-lstl8tp5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fplop9lx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 71\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbow: countVector\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 40\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000999363790360081\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnetwork: rnn\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnrows: 140\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 19\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\jespe\\git\\550dat\\prosjekt\\wandb\\run-20240419_074838-fplop9lx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/j-soberg/RNNs%20and%20You/runs/fplop9lx' target=\"_blank\">worldly-sweep-5</a></strong> to <a href='https://wandb.ai/j-soberg/RNNs%20and%20You' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/j-soberg/RNNs%20and%20You/sweeps/48m0nanw' target=\"_blank\">https://wandb.ai/j-soberg/RNNs%20and%20You/sweeps/48m0nanw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/j-soberg/RNNs%20and%20You' target=\"_blank\">https://wandb.ai/j-soberg/RNNs%20and%20You</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/j-soberg/RNNs%20and%20You/sweeps/48m0nanw' target=\"_blank\">https://wandb.ai/j-soberg/RNNs%20and%20You/sweeps/48m0nanw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/j-soberg/RNNs%20and%20You/runs/fplop9lx' target=\"_blank\">https://wandb.ai/j-soberg/RNNs%20and%20You/runs/fplop9lx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4646\n",
      "loss: 2.3027725219726562  [71.0/140]\n",
      "Test Error: \n",
      " Accuracy: 0.17142857142857143, Precision: 0.16797438672438672, recall: 0.16837492856674444, f1: 0.16053138967185615, Avg loss: 2.300985336303711 \n",
      "\n",
      "loss: 2.3009331226348877  [71.0/140]\n",
      "Test Error: \n",
      " Accuracy: 0.18571428571428572, Precision: 0.18852540433422788, recall: 0.1892357344275503, f1: 0.18375636044326746, Avg loss: 2.3008843660354614 \n",
      "\n",
      "loss: 2.2994914054870605  [71.0/140]\n",
      "Test Error: \n",
      " Accuracy: 0.18571428571428572, Precision: 0.18828208556149734, recall: 0.1690812980710679, f1: 0.1744522937881572, Avg loss: 2.3007102012634277 \n",
      "\n",
      "loss: 2.2957100868225098  [71.0/140]\n",
      "Test Error: \n",
      " Accuracy: 0.22142857142857142, Precision: 0.21951479076479075, recall: 0.21363258012234992, f1: 0.21255570321898923, Avg loss: 2.3002768754959106 \n",
      "\n",
      "loss: 2.2932662963867188  [71.0/140]\n",
      "Test Error: \n",
      " Accuracy: 0.19285714285714287, Precision: 0.18537464985994398, recall: 0.18772275465370095, f1: 0.18032446646298636, Avg loss: 2.299942970275879 \n",
      "\n",
      "loss: 2.2917678356170654  [71.0/140]\n",
      "Test Error: \n",
      " Accuracy: 0.22142857142857142, Precision: 0.22322371256194784, recall: 0.21098929203788538, f1: 0.20619544367190965, Avg loss: 2.299766421318054 \n",
      "\n",
      "loss: 2.288010835647583  [71.0/140]\n",
      "Test Error: \n",
      " Accuracy: 0.2, Precision: 0.19967907092907095, recall: 0.19060737003831635, f1: 0.19257706838351998, Avg loss: 2.2993866205215454 \n",
      "\n",
      "loss: 2.2854788303375244  [71.0/140]\n",
      "Test Error: \n",
      " Accuracy: 0.25, Precision: 0.2476938641069076, recall: 0.23819231706060345, f1: 0.23650777835935158, Avg loss: 2.2984131574630737 \n",
      "\n",
      "loss: 2.2815520763397217  [71.0/140]\n",
      "Test Error: \n",
      " Accuracy: 0.2642857142857143, Precision: 0.26645363408521305, recall: 0.25391177875832605, f1: 0.25359633659146397, Avg loss: 2.2984726428985596 \n",
      "\n",
      "loss: 2.276865243911743  [71.0/140]\n",
      "Test Error: \n",
      " Accuracy: 0.2714285714285714, Precision: 0.26362741584928284, recall: 0.25705280439935174, f1: 0.2530136129574782, Avg loss: 2.2977811098098755 \n",
      "\n",
      "loss: 2.2741119861602783  [71.0/140]\n",
      "Test Error: \n",
      " Accuracy: 0.22857142857142856, Precision: 0.20420246420246418, recall: 0.21334794787480207, f1: 0.20213888461714546, Avg loss: 2.2972103357315063 \n",
      "\n",
      "loss: 2.2703025341033936  [71.0/140]\n",
      "Test Error: \n",
      " Accuracy: 0.3142857142857143, Precision: 0.28874590321958743, recall: 0.28671910570248166, f1: 0.28238495983288703, Avg loss: 2.296414017677307 \n",
      "\n",
      "loss: 2.2646725177764893  [71.0/140]\n",
      "Test Error: \n",
      " Accuracy: 0.3, Precision: 0.2791179653679654, recall: 0.27985570482373545, f1: 0.27399631913425015, Avg loss: 2.2961764335632324 \n",
      "\n",
      "loss: 2.2620840072631836  [71.0/140]\n",
      "Test Error: \n",
      " Accuracy: 0.35, Precision: 0.3374547674547675, recall: 0.3323876038709798, f1: 0.32966373250198666, Avg loss: 2.2949979305267334 \n",
      "\n",
      "loss: 2.256798028945923  [71.0/140]\n",
      "Test Error: \n",
      " Accuracy: 0.32142857142857145, Precision: 0.3024209124209124, recall: 0.30614293208922366, f1: 0.29848363069482675, Avg loss: 2.2946516275405884 \n",
      "\n",
      "loss: 2.2497506141662598  [71.0/140]\n",
      "Test Error: \n",
      " Accuracy: 0.35714285714285715, Precision: 0.32815170940170935, recall: 0.32368597940848576, f1: 0.32121311254238083, Avg loss: 2.294040560722351 \n",
      "\n",
      "loss: 2.2447409629821777  [71.0/140]\n",
      "Test Error: \n",
      " Accuracy: 0.37857142857142856, Precision: 0.34577801827801824, recall: 0.3539221307251998, f1: 0.34331863258595374, Avg loss: 2.2929409742355347 \n",
      "\n",
      "loss: 2.2399814128875732  [71.0/140]\n",
      "Test Error: \n",
      " Accuracy: 0.42142857142857143, Precision: 0.39639790764790767, recall: 0.40651171505391454, f1: 0.3965986760318574, Avg loss: 2.2929062843322754 \n",
      "\n",
      "loss: 2.2351276874542236  [71.0/140]\n",
      "Test Error: \n",
      " Accuracy: 0.36428571428571427, Precision: 0.34011446886446883, recall: 0.3364436778055704, f1: 0.33143849826776656, Avg loss: 2.2918859720230103 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>▁▁▁▂▂▂▂▃▄▄▃▅▅▆▅▆▇█▆</td></tr><tr><td>Macro-f1-score</td><td>▁▂▁▃▂▂▂▃▄▄▂▅▄▆▅▆▆█▆</td></tr><tr><td>Precision</td><td>▁▂▂▃▂▃▂▃▄▄▂▅▄▆▅▆▆█▆</td></tr><tr><td>Recall</td><td>▁▂▁▂▂▂▂▃▄▄▂▄▄▆▅▆▆█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>0.36429</td></tr><tr><td>Macro-f1-score</td><td>0.33144</td></tr><tr><td>Precision</td><td>0.34011</td></tr><tr><td>Recall</td><td>0.33644</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">worldly-sweep-5</strong> at: <a href='https://wandb.ai/j-soberg/RNNs%20and%20You/runs/fplop9lx' target=\"_blank\">https://wandb.ai/j-soberg/RNNs%20and%20You/runs/fplop9lx</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240419_074838-fplop9lx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, sweep, count=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
